{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNll7i7xUYuE61WE5TFNt84",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravm999/LLMs/blob/main/RAG_vs_Agentic_RAG_CPG_Sales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG for CPG Sales"
      ],
      "metadata": {
        "id": "jhiWrYjiudSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj7tgxVmsDtF",
        "outputId": "1cf95a1a-7a59-4b6c-a977-358f04611f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ],
      "source": [
        "# Google Colab Code for RAG\n",
        "\n",
        "# Step 1: Install necessary libraries\n",
        "!pip install transformers faiss-cpu pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import necessary modules\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import faiss"
      ],
      "metadata": {
        "id": "U0fGHQ7msHa0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load sample dataset\n",
        "data = {\n",
        "    'Region': ['North', 'South', 'East', 'West'],\n",
        "    'Sales Data': ['5000 units', '3000 units', '8000 units', '2000 units'],\n",
        "    'Customer Feedback': ['Positive reviews, some issues with stock.',\n",
        "                          'Moderate reviews, mentions of better alternatives.',\n",
        "                          'High demand, positive reviews.',\n",
        "                          'Low sales, customers demand discounts.'],\n",
        "    'Competitor Activity': ['Launched a discount.',\n",
        "                            'No competitor action.',\n",
        "                            'Running heavy ads.',\n",
        "                            'Aggressive discounts.']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUwypkIcsKcf",
        "outputId": "15852d30-80df-49cf-ee0c-eb172df29fb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Region  Sales Data                                  Customer Feedback  \\\n",
            "0  North  5000 units          Positive reviews, some issues with stock.   \n",
            "1  South  3000 units  Moderate reviews, mentions of better alternati...   \n",
            "2   East  8000 units                     High demand, positive reviews.   \n",
            "3   West  2000 units             Low sales, customers demand discounts.   \n",
            "\n",
            "     Competitor Activity  \n",
            "0   Launched a discount.  \n",
            "1  No competitor action.  \n",
            "2     Running heavy ads.  \n",
            "3  Aggressive discounts.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize a retrieval-augmented generation model (e.g., T5)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
        "rag = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Step 5: Build the FAISS index (for retrieval)\n",
        "import numpy as np # import the numpy module\n",
        "def build_faiss_index(df):\n",
        "    embeddings = [] # create a list to store all the embeddings\n",
        "    for i, row in df.iterrows():\n",
        "        text = f\"Region: {row['Region']}, Sales: {row['Sales Data']}, Feedback: {row['Customer Feedback']}, Competitor Activity: {row['Competitor Activity']}\"\n",
        "        input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "        embedding = model.get_encoder()(input_ids).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        embeddings.append(embedding) # append the embedding to the list\n",
        "    embeddings = np.concatenate(embeddings, axis=0) # concatenate all embeddings into a single array\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])  # Use the correct dimension for the index\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "index = build_faiss_index(df)\n",
        "\n",
        "# Step 6: Retrieve information\n",
        "def retrieve(query):\n",
        "    query_embedding = model.get_encoder()(tokenizer.encode(query, return_tensors='pt')).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    D, I = index.search(query_embedding, 3)  # Top 3 closest regions\n",
        "    for i in I[0]:\n",
        "        print(f\"Retrieved Info: {df.iloc[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERipZC7GsP8C",
        "outputId": "129b2001-9e17-476a-82c6-742513838778"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Test the RAG pipeline\n",
        "query = \"Why did the East region perform better than others?\"\n",
        "retrieve(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFAiW8wKscKj",
        "outputId": "9a5f3a4d-3310-4f4b-92b3-587f846a0c73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Info: Region                                           East\n",
            "Sales Data                                 8000 units\n",
            "Customer Feedback      High demand, positive reviews.\n",
            "Competitor Activity                Running heavy ads.\n",
            "Name: 2, dtype: object\n",
            "Retrieved Info: Region                                                   West\n",
            "Sales Data                                         2000 units\n",
            "Customer Feedback      Low sales, customers demand discounts.\n",
            "Competitor Activity                     Aggressive discounts.\n",
            "Name: 3, dtype: object\n",
            "Retrieved Info: Region                                                     North\n",
            "Sales Data                                            5000 units\n",
            "Customer Feedback      Positive reviews, some issues with stock.\n",
            "Competitor Activity                         Launched a discount.\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to generate a report based on retrieved data\n",
        "response = rag(f\"Why did the East region perform better than others? {df.iloc[2]['Sales Data']} {df.iloc[2]['Customer Feedback']} {df.iloc[2]['Competitor Activity']}\")\n",
        "print(\"RAG Response: \", response[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtVpaXQDtel1",
        "outputId": "609a74e5-cf75-4602-f7e3-f490b64861ba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Response:  East region perform better than others\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG for CPG Sales"
      ],
      "metadata": {
        "id": "yrCH_q6Fuiyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Code for Agentic RAG\n",
        "\n",
        "# Step 1: Install necessary libraries\n",
        "!pip install transformers faiss-cpu pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41cmOnIPubqD",
        "outputId": "5d0d39b6-85e9-4cfd-e873-11a1a8ffd930"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import necessary modules\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import faiss\n",
        "\n",
        "# Step 3: Load sample dataset (same as above)\n",
        "data = {\n",
        "    'Region': ['North', 'South', 'East', 'West'],\n",
        "    'Sales Data': ['5000 units', '3000 units', '8000 units', '2000 units'],\n",
        "    'Customer Feedback': ['Positive reviews, some issues with stock.',\n",
        "                          'Moderate reviews, mentions of better alternatives.',\n",
        "                          'High demand, positive reviews.',\n",
        "                          'Low sales, customers demand discounts.'],\n",
        "    'Competitor Activity': ['Launched a discount.',\n",
        "                            'No competitor action.',\n",
        "                            'Running heavy ads.',\n",
        "                            'Aggressive discounts.']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baDY1Yt1uqzH",
        "outputId": "b103c595-a6ec-41b1-cb5b-ab0a53f8439b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Region  Sales Data                                  Customer Feedback  \\\n",
            "0  North  5000 units          Positive reviews, some issues with stock.   \n",
            "1  South  3000 units  Moderate reviews, mentions of better alternati...   \n",
            "2   East  8000 units                     High demand, positive reviews.   \n",
            "3   West  2000 units             Low sales, customers demand discounts.   \n",
            "\n",
            "     Competitor Activity  \n",
            "0   Launched a discount.  \n",
            "1  No competitor action.  \n",
            "2     Running heavy ads.  \n",
            "3  Aggressive discounts.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize RAG and FAISS as in the RAG example\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
        "rag = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "def build_faiss_index(df):\n",
        "    embeddings = [] # create a list to store the embeddings\n",
        "    for i, row in df.iterrows():\n",
        "        text = f\"Region: {row['Region']}, Sales: {row['Sales Data']}, Feedback: {row['Customer Feedback']}, Competitor Activity: {row['Competitor Activity']}\"\n",
        "        input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "        embedding = model.get_encoder()(input_ids).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "        embeddings.append(embedding) # append the embedding to the list\n",
        "\n",
        "    # get the dimensionality of the embeddings\n",
        "    dim = embeddings[0].shape[1]\n",
        "    # create the Faiss index with the correct dimensionality\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    # add the embeddings to the index\n",
        "    index.add(np.array(embeddings).reshape(len(embeddings), dim))\n",
        "    return index\n",
        "\n",
        "index = build_faiss_index(df)\n",
        "\n",
        "# Step 5: Agentic decision-making function\n",
        "def agentic_decision(query):\n",
        "    query_embedding = model.get_encoder()(tokenizer.encode(query, return_tensors='pt')).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    D, I = index.search(query_embedding, 1)  # Find the closest region\n",
        "\n",
        "    closest_region = df.iloc[I[0][0]]\n",
        "    print(f\"Agentic Decision-Making for Region: {closest_region['Region']}\")\n",
        "\n",
        "    # Autonomous actions based on retrieved information (e.g., adjust discount strategy)\n",
        "    if closest_region['Sales Data'] == '2000 units':\n",
        "        print(\"Low sales detected. Action: Increase discount to 20% for the West region.\")\n",
        "    else:\n",
        "        print(f\"Region {closest_region['Region']} is performing well. No immediate action required.\")\n",
        "\n",
        "# Step 6: Test the Agentic RAG model\n",
        "query = \"How should we adjust promotion strategies based on sales performance?\"\n",
        "agentic_decision(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHyJ0F1avfB0",
        "outputId": "443973b9-bfa4-4b6b-d128-6ba35ee493c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic Decision-Making for Region: West\n",
            "Low sales detected. Action: Increase discount to 20% for the West region.\n"
          ]
        }
      ]
    }
  ]
}